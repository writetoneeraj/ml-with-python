{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\nimport math\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import tree\nimport cv2 as cv\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Table of Contents\n\n[Regression](#regression)\n\n[Logistic Regression](#logistic_regression)\n\n[Confusion Matrix](#confusion_matrix)\n\n[ROC_AUC Curve](#roc_auc)\n\n[Decision Tree](#decision_trees)\n"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"regression\"></a>\n# What is Regression?\n\nRegression is a method to find out relationship between dependent variable and one or more independent variables. Regression provides the strength of the relationship. \n\n### We fit line of regrssion by using formulae y = mx + b, where m is slope and y is intercept.\n\nBut for linear classification this regression line might not be appropriate. Lets see why?"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load data\n\nheart = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove duplicates from the data.\n\nheart = heart.drop_duplicates()\nheart.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Describe statistics for numerical fields of data.\n\nheart.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get slope and intercept using numpy library.\n\nm,b = np.polyfit(heart['age'], heart['trestbps'], 1) # m is slope and b is intercept\nprint(m,b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate slope and intercept manually.\n\ndef best_fit_slope_and_intercept(xs,ys):\n    m = (((np.mean(xs)*np.mean(ys)) - np.mean(xs*ys)) /\n         ((np.mean(xs)*np.mean(xs)) - np.mean(xs*xs)))\n    \n    b = np.mean(ys) - m*np.mean(xs)\n    \n    return m, b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m1, b1 = best_fit_slope_and_intercept(heart['age'].values, heart['trestbps'].values)\nprint(m1, b1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get regression line. It gives new y values using calculated slope and intercept.\n\nregression_line = [(m*x)+b for x in heart['age'].values]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot regression line \n\nplt.figure(figsize=(15,5))\nplt.scatter(heart['age'], heart['trestbps'], color='#003F72')\nplt.plot(heart['age'], regression_line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets plot BP and target for all heart patients and fit regression line for the data.\n\nstyle.use('ggplot')\nheart_temp = heart.copy()\nm,b = np.polyfit(heart_temp['trestbps'], heart_temp['target'], 1)\nregression_line = [(m*x)+b for x in heart_temp['trestbps'].values]\nplt.figure(figsize=(15,5))\nplt.scatter(heart_temp['trestbps'], heart_temp['target'], color='#003F72')\nplt.plot(heart_temp['trestbps'], regression_line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# If we change existing data points of BP to 300 where ever BP is 200, our regression line predict wrongly BP with value 300. \n# This shows that linear regression is very sensitive to outliers. And if we get more such data fitted line can misclassify \n# many more data points. This is one of the reasons why linear regression does not fit for classifying binary outputs i.e.\n# 0's and 1's. And that's where we use logistic regression.\n\nheart_temp = heart.copy()\nheart_temp['trestbps'].replace({200:300}, inplace=True)\nm,b = np.polyfit(heart_temp['trestbps'], heart_temp['target'], 1)\n#regression_line = [(m*x)+b for x in heart_temp['trestbps'].values]\nregression_line = np.dot(m, heart_temp['trestbps']) + b\nplt.figure(figsize=(15,5))\nplt.scatter(heart_temp['trestbps'], heart_temp['target'], color='#003F72')\nplt.plot(heart_temp['trestbps'], regression_line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#target - have disease or not (1=yes, 0=no)\nsns.countplot(x=\"target\", data=heart, palette=\"bwr\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"logistic_regression\"></a>\n\n# Logistic Regression\n\nTo solve this issue we need some formulae which provides values between 0 to 1 that means probability of being either true or false. Such formulae is sigmoid or logit function. Algorithm which use sigmoid is Logistic Regression.\n\n$$ h_ \\theta (x) =  \\frac{\\mathrm{1} }{\\mathrm{1} + e^- \\theta^Tx }  $$ "},{"metadata":{"trusted":true},"cell_type":"code","source":"def sigmoid(x):\n  return 1 / (1 + np.exp(-x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z = heart['restecg']\na = sigmoid(z)\nprint(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(z, a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = heart.target.values\nx = heart.drop(['target'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracies = {}\n\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\nacc = lr.score(x_test,y_test)*100\n\naccuracies['Logistic Regression'] = acc\nprint(\"Test Accuracy {:.2f}%\".format(acc))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"confusion_matrix\"></a>\n\n# Confusion matrix \nConfusion matrix provides data which describes performance of the classification model. Matrix data is calculated on test data for which true values are known. It gives number for correct and incorrect predictions made by the model.\n\nData in four columns represents:\n\nTrue Positive - Actually positive and predicted also positive.\n\nFalse Positive - Actually positive but predicted as negative.\n\nFalse Negative - Actually negative but predicted as positive.\n\nTrue Negative - Actually negative and predicted also negative.\n\nAccuracy = True positive + True Negative / (TP + TN + FP + FN)\n\nFalse positive also known as Type 1 error\n\nFalse Negative also known as Type 2 error\n\nType 2 errors are more dangerous than type 1\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"score = pd.DataFrame({\"Predicted\":lr.predict(x_test),\"Actual\":y_test})\npd.options.display.max_rows=100\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(score.Actual, score.Predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#precision = TP/TP+FP\nprecision = 22/26 *100\nprecision","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = 52/61 * 100\naccuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"roc_auc\"></a>\n\n# ROC-AUC curve\n\nROC curve helps in determining what should be the right threshold value.\n\nOn this curve on y axis we plot sensitivity i.e out of total positive or true cases how much were predicted correctly i.e what proportion of data was correctly classified out of total positive or true values.\n\nSensitivity/TPR/Recall = TP/TP+FN\n\nSpecificity = TN/TN + FP\n\nOn x axis we plot False Positive rate i.e ration of negative cases predicted as positive.\nFPR = 1-Specificity = FP/FP+TN\n\nPrecision = TP / TP + FP\n\nSome times in data with imbalances like people not having heart disease are much much more than people having disease we can replace FPR with Precision.\n\n\nAUC gives area under curve and helps in comparring the models. More AUC is better than less AUC.\n\nIn below curve the classes are seperated correctly and it is a ideal situation. Positive classes are classified as positive and negative classes considered as negative. AUC=1\n\n![ROC Class Separability](https://miro.medium.com/max/528/1*Uu-t4pOotRQFoyrfqEvIEg.png)"},{"metadata":{},"cell_type":"markdown","source":"![ROC AUC Curve](https://miro.medium.com/max/323/1*HmVIhSKznoW8tFsCLeQjRw.png)\n\nIn super important domains like risky health diseases we cannot efford wrong prediction of type2 errors, so we reduce threshold value. Suppose we reduce threshold to 0.3 so anything of higher probability from 0.3 will be considered as True(that means person has disease)."},{"metadata":{},"cell_type":"markdown","source":"Second situation where there is some overlap of positive and negative classes \ni.e few positives are classified as negative and few negatives are classified as positive. Overlapping introduce type1 and type2 errors. Depending upon the threshold, we can minimize or maximize them. When AUC is 0.7, it means there is 70% chance that model will be able to distinguish between positive class and negative class.\n\n![Overlapping classes](https://miro.medium.com/max/507/1*yF8hvKR9eNfqqej2JnVKzg.png)\n\nROC AUC curve will look like\n\n![ROC_AUC_Overlapping](https://miro.medium.com/max/340/1*-tPXUvvNIZDbqXP0qqYNuQ.png)\n"},{"metadata":{},"cell_type":"markdown","source":"Worst case where model not able to classify anything. In any situation model can not classify anything. AUC = 0.5\nTPR = 1 that means all positive cases are correctly classified as positive.\nFPR = 1 that means all negative cases are incorrectly classified as positive.\n\nThe point on ROC(1,1) means even we classified all positives correctly but all negatives are misclassified as positive.\n\n\nAUC looks like \n\n![AUC_0.5](https://miro.medium.com/max/430/1*iLW_BrJZRI0UZSflfMrmZQ.png)\n\n![ROC_AUC_0.5](https://miro.medium.com/max/363/1*k_MPO2Q9bLNH9k4Wlk6v_g.png)"},{"metadata":{},"cell_type":"markdown","source":"AUC = 0 \nAll positives considered as negatives and all negatives considered as positives.\n\n![AUC_0](https://miro.medium.com/max/556/1*aUZ7H-Lw74KSucoLlj1pgw.png)\n\n![ROC_AUC_0](https://miro.medium.com/max/300/1*H7JGQbaa06BUab6tvGNZKg.png)\n\nSource of all images - https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5"},{"metadata":{"trusted":true},"cell_type":"code","source":"auc = roc_auc_score(score.Actual, score.Predicted)\nprint(auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(score.Actual, score.Predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(fpr, tpr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<a id=\"decision_trees\"></a>\n       \n# Decision Trees\n\nDecision trees are flowcharts like trees where every node is a test criteria. Every branch is output of the test and each leaf node holds a class label.\nDecision trees can work on high dimensional data. Decision trees does not require domain knowledge."},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature_names = ['age', 'sex', 'cp', 'ca', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach','thal']\nfeature_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n       'exang', 'oldpeak', 'slope', 'ca', 'thal']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = heart[feature_names]\nY = heart.target\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=23)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree = DecisionTreeClassifier(criterion='entropy', max_depth=9)\ndtree.fit(x_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree.score(x_test, y_test) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_dtree = pd.DataFrame({\"Predicted\":dtree.predict(x_test),\"Actual\":y_test})\npd.options.display.max_rows=100\nconfusion_matrix(score_dtree.Actual, score_dtree.Predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(25,20))\n_ = tree.plot_tree(dtree, \n                   feature_names= list(feature_names),  \n                   class_names=list(['1','0']),\n                   filled=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = heart.drop('target', axis=1)\nY = heart.target\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\nrfc = RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0, max_depth=10)\nrfc.fit(x_train, y_train)\nrfc.score(x_test, y_test) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_rfc = pd.DataFrame({\"Predicted\":rfc.predict(x_test),\"Actual\":y_test})\npd.options.display.max_rows=100\nconfusion_matrix(score_rfc.Actual, score_rfc.Predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator_limited = rfc.estimators_[0]\nestimator_limited\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import export_graphviz\n\nexport_graphviz(estimator_limited, out_file='tree_limited.dot', feature_names = list(feature_names),\n                class_names = list(set(str(heart['target']))),\n                rounded = True, proportion = False, precision = 2, filled = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!dot -Tpng tree_limited.dot -o tree_limited.png -Gdpi=600","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(filename = 'tree_limited.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_dtree = roc_auc_score(score_dtree.Actual, score_dtree.Predicted)\nprint(auc_dtree)\nfpr_dtree, tpr_dtree, thresholds_dtree = roc_curve(score_dtree.Actual, score_dtree.Predicted)\nplot_roc_curve(fpr_dtree, tpr_dtree)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_rfc = roc_auc_score(score_rfc.Actual, score_rfc.Predicted)\nprint(auc_rfc)\nfpr_rfc, tpr_rfc, thresholds_rfc = roc_curve(score_rfc.Actual, score_rfc.Predicted)\nprint(thresholds_rfc)\nplot_roc_curve(fpr_rfc, tpr_rfc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(0).clf()\nplt.plot(fpr, tpr, color='orange', label=\"Logistic Regression, auc=\"+str(accuracy))\nplt.plot(fpr_dtree, tpr_dtree, color='blue', label=\"Decision Tree, auc=\"+str(auc_dtree))\nplt.plot(fpr_rfc, tpr_rfc, color='red', label=\"Random Forest, auc=\"+str(auc_rfc))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('1-Specificity(False Positive Rate)')\nplt.ylabel('Sensitivity(True Positive Rate)')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}