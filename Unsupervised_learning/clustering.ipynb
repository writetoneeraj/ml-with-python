{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#! conda install -c conda-forge kneed -y","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n#from kneed import KneeLocator\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"<a id='clusteringtypes'></a>\n\n# Types of Clustering\n\n1. Non overlapping clustering(kmeans clustering) - Data points does not overlap on each other.\n\n2. Overlapping clustering (C/Fuzzy clustering) - Data points overlap on each other.\n\n3. Hierarchial clustering\n"},{"metadata":{},"cell_type":"markdown","source":"In this notebook we will talk about kmeans where k is number of clusters we need. We define two things for this algorithm:\n\n1. Number of clusters - It might come from domain knowledge or we choose number of clusters with minimum sum of square distance from centroid and data points in the cluster.\n\n2. Centroids - This can be random value for a cluster.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"heart = pd.read_csv('../input/heart-disease-uci/heart.csv')\nheart = heart.drop_duplicates()\ny = heart.target\nheart = heart.drop('target', axis = 1)\nheart.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Suppose we start k = 3\nk=3\ncentroids = {i+1:[np.random.randint(0,302), np.random.randint(0,302)] for i in range(k)}\nprint(centroids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_val = heart.values\nX = heart[['chol','thalach']].values\nscaler = StandardScaler()\nx_std = scaler.fit_transform(X=heart[['chol','thalach']])\nx_min_max = MinMaxScaler.fit_transform(X=heart[['chol','thalach']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(init=\"random\", n_clusters=5, random_state=42)\nkmeans.fit(x_std)\ny = kmeans.fit_predict(x_std)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart['cluster'] = y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart[heart['cluster']==1].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart[heart['cluster'] == 0].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart[heart['cluster'] == 2].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart[heart['cluster'] == 1].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[y == 0, 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualising the clusters\n#Scatter plotting for (x,y) with label 1 as Cluster 1 in color c = red and points in size s = 50\nplt.scatter(X[y == 0, 0], X[y == 0, 1], s = 50, c = 'red', label = 'Cluster 1')\n#Scatter plotting for (x,y) with label 2 as Cluster 2 in color c = blue and points in size s = 50\nplt.scatter(X[y == 1, 0], X[y == 1, 1], s = 50, c = 'blue', label = 'Cluster 2')\n#Scatter plotting for (x,y) with label 3 as Cluster 3 in color c = green and points in size s = 50\nplt.scatter(X[y == 2, 0], X[y == 2, 1], s = 50, c = 'green', label = 'Cluster 3')\n#Scatter plotting for (x,y) with label 3 as Cluster 3 in color c = green and points in size s = 50\nplt.scatter(X[y == 3, 0], X[y == 3, 1], s = 50, c = 'orange', label = 'Cluster 4')\n#Scatter plotting for (x,y) with label 3 as Cluster 3 in color c = green and points in size s = 50\nplt.scatter(X[y == 4, 0], X[y == 4, 1], s = 50, c = 'pink', label = 'Cluster 5')\n\n#Scatter plotting the centroids with label = 'Centroids' in color c = cyan and points in size s = 100\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 100, c = 'cyan', label = 'Centroids')\n\nplt.title('Heart Patient Clusters')\nplt.xlabel('Cholestrol')\nplt.ylabel('Thalach')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Silhouette Score\n\nIf the ground truth labels are not known, evaluation must be performed using the model itself. The Silhouette Coefficient (sklearn.metrics.silhouette_score) is an example of such an evaluation, where a higher Silhouette Coefficient score relates to a model with better defined clusters. The Silhouette Coefficient is defined for each sample and is composed of two scores:\n\na: The mean distance between a sample and all other points in the same class.\n\nb: The mean distance between a sample and all other points in the next nearest cluster.\n\nThe Silhouette Coefficient s for a single sample is then given as:\n\n$$ ss = \\frac {b - a}{max(a,b)} $$"},{"metadata":{"trusted":true},"cell_type":"code","source":"sse = []\nsilhouette_scores = []\nfor k in range(2,11):\n    kmeans = KMeans(init=\"random\", n_clusters=k, random_state=42)\n    kmeans.fit(X)\n    sse.append(kmeans.inertia_)\n    sc = silhouette_score(X, kmeans.labels_)\n    silhouette_scores.append(sc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(2, 11), silhouette_scores)\nplt.xticks(range(2, 11))\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"Silhouette Coefficient\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(2, 11), sse)\nplt.xticks(range(2, 11))\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"SSE\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"References\n\n1. [Updating centroids](https://towardsdatascience.com/k-means-clustering-for-beginners-2dc7b2994a4)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}